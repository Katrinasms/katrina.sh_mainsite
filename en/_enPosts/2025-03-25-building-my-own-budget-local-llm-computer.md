---
layout: posts
title: AI - Building my own budget local LLM computer
description: With the increasing demand in working with LLM, instead of paying for API key, I am thinking about building my own local LLM model. 
lang: en
imageSrc: /assets/images/blog/local-computer.png
tag: [local-llm-computer]
mayLikes: [CDN-for-image]
---

## **My Struggle:**
With the increasing demand in working with LLM, instead of paying for API key, I am thinking about building my own local LLM model. 
However, I am a bit new to computer hardware. So, I plan to research first and sort out what I plan to buy at the end. My budget is around 1000 - 3000 USD. 

### Step 1: Understanding what is inside the computer (Week of 20 Mar 2025)
First, I tried to have basic understanding, about things that I need and explore to different option.

Basic Components required:
- CPU
- GPU (**for higher performance)
- RAM
- SSD
- Power
- Motherboard
- Cooler / Fan
- The Box

Since there is many components, the possible combination is a lot, let's see how to find a balance between the price and performance for my use-case:)!

> At the same time, as I am located in Hong Kong, I realized that the price of GPU display card, especially the 50 series is pretty expansive (at least 50% more than the price stated in official website) and also out of stock. Wonder what card I would end up with ;,)

### Step 2: Understanding the relationship of hardware and performance
TBC